{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<h1>Analyzing Wikipedia Pages</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "os.listdir(\"wiki\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Count the number of files in the wiki directory\n",
    "len(os.listdir(\"wiki\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print one file to see the structure\n",
    "with open(\"wiki/Egg_coffee.html\") as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Reading all the file's content</h3>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "import time\n",
    "\n",
    "pool = concurrent.futures.ThreadPoolExecutor(max_workers=4)\n",
    "\n",
    "def read_data(filename):\n",
    "    with open(filename) as f:\n",
    "        data = f.read()\n",
    "    return data\n",
    "\n",
    "start = time.time()\n",
    "filenames = [\"wiki/{}\".format(f) for f in os.listdir(\"wiki\")]\n",
    "content = pool.map(read_data, filenames)\n",
    "content = list(content)\n",
    "\n",
    "end = time.time()\n",
    "print(end - start)\n",
    "articles = [f.replace(\".html\", \"\").replace(\"wiki/\", \"\") for f in filenames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Remove Markup\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def parse_html(html):\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    return str(soup.find_all(\"div\", id=\"content\")[0])\n",
    "\n",
    "start = time.time()\n",
    "pool = concurrent.futures.ProcessPoolExecutor(max_workers=3)\n",
    "parsed = pool.map(parse_html, content)\n",
    "parsed = list(parsed)\n",
    "end = time.time()\n",
    "\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Find Common Tags\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def count_tags(html):\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    tags = {}\n",
    "    for tag in soup.find_all():\n",
    "        if tag.name not in tags:\n",
    "            tags[tag.name] = 0\n",
    "        tags[tag.name] += 1\n",
    "    return tags\n",
    "\n",
    "start = time.time()\n",
    "pool = concurrent.futures.ProcessPoolExecutor(max_workers=3)\n",
    "tags = pool.map(count_tags, parsed)\n",
    "tags = list(tags)\n",
    "\n",
    "tag_counts = {}\n",
    "for tag in tags:\n",
    "    for k,v in tag.items():\n",
    "        if k not in tag_counts:\n",
    "            tag_counts[k] = 0\n",
    "        tag_counts[k] += v\n",
    "end = time.time()\n",
    "\n",
    "print(end - start)\n",
    "tag_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
